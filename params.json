{"name":"TribeFlow","tagline":"TribeFlow source code","body":"<a name=\"top\"></a>\r\nTribeFlow\r\n=========\r\n\r\n1. [Top](#top)\r\n2. [Datasets](#data)\r\n3. [Competing Methods](#competition)\r\n\r\nContains the TribeFlow (previously node-sherlock) source code.\r\n\r\nDependencies\r\n------------\r\n\r\nThe python dependencies are:\r\n\r\n* Mpi4Py\r\n* numpy\r\n* scipy\r\n* cython\r\n* pandas\r\n* plac\r\n\r\nYou will also need to install and setup: \r\n\r\n* OpenMP\r\n* MPI\r\n\r\nHow to install dependencies\r\n---------------------------\r\n\r\n*Easy way:* Install [Anaconda Python](https://www.continuum.io/) and \r\nset it up as your default enviroment.\r\n\r\n*Hard way:* Use pip or your package manager to install the dependencies. \r\n\r\n```bash\r\npip install numpy\r\npip install scipy\r\npip install cython\r\npip install pandas\r\npip install mpi4py\r\npip install plac\r\n```\r\n\r\nUse or package manager (*apt* on Ubuntu, *HomeBrew* on a mac) to install\r\nOpenMP and MPI. These are the managers I tested with. Should work on any\r\nother environment.\r\n\r\nHow to compile\r\n--------------\r\n\r\nSimply type `make`\r\n\r\n```bash\r\nmake\r\n```\r\n\r\nHow to use\r\n----------\r\n\r\nEither use `python setup.py install` to install the packager or just use it from\r\nthe package folder using the `run_script.sh` command.\r\n\r\n*How to parse datasets:* Use the `scripts/trace_converter.py` script. It has a help.\r\n\r\nFor command line help:\r\n\r\n```bash\r\n$ python scripts/trace_converter.py -h\r\n$ python main.py -h\r\n```\r\n\r\nRunning with mpi\r\n\r\n```bash\r\n$ mpiexec -np 4 python main.py [OPTIONS]\r\n```\r\n\r\nExample\r\n-------\r\n\r\nThe example below is the same code used for every result in the paper. It runs\r\nTribeFlow with the options used in every result in the paper. Explaining the\r\nparameters:\r\n\r\n   * *-np 4* Number of cores for execution.\r\n   * *100* topics.\r\n   * *output.h5* model file.\r\n   * *--kernel eccdf* The kernel heuristic for inter-event time estimation. ECCDF\r\n     based as per described on the paper. We also have a t-student kernel.\r\n   * *--residency_priors 1 99* The priors for the inter-event time estimation.\r\n   * *--leaveout 0.3* Number of transitions to leaveout.\r\n   * *--num_iter 2000* Number of iterations.\r\n   * *--num_batches 20* Number of split/merge moves.\r\n\r\n```bash\r\n$ mpiexec -np 4 python main.py trace.dat 100 output.h5 \\\r\n    --kernel eccdf --residency_priors 1 99 \\\r\n    --leaveout 0.3 --num_iter 2000 --num_batches 20\r\n```\r\n\r\n<a name=\"data\"></a>\r\nDatasets\r\n========\r\n\r\nTo come!\r\n\r\n<a name=\"competition\"></a>\r\nCompeting Methods\r\n=================\r\n\r\n* [PRLME](http://github.com/flaviovdf/plme)\r\n* [FPMC](http://github.com/flaviovdf/fpmc)\r\n* [LME](http://www.cs.cornell.edu/people/tj/playlists/index.html)\r\n* [Gravity Model](https://github.com/flaviovdf/tribeflow/blob/master/scripts/gravity_model.py)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}